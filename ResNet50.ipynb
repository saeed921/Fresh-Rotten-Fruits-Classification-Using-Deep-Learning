{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet50.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMV4hGKGJd_L"
      },
      "source": [
        "from keras.layers import Input, Lambda, Dense, Flatten\n",
        "from keras.models import Model\n",
        "from keras.applications.resnet import ResNet50\n",
        "from keras.applications.resnet import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "IMAGE_SIZE = [224,224]\n",
        "\n",
        "training_path = \"/content/drive/MyDrive/dataset/data/train\"\n",
        "testing_path = \"/content/drive/MyDrive/dataset/data/test\"\n",
        "\n",
        "resnet = ResNet50(input_shape = IMAGE_SIZE + [3], weights = 'imagenet',include_top = False)\n",
        "for layer in resnet.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "x = Flatten()(resnet.output)\n",
        "prediction = Dense(6,activation = 'softmax')(x)\n",
        "\n",
        "model = Model(inputs = resnet.input, outputs = prediction)\n",
        "model.summary()\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "optimizer = 'adam',\n",
        "metrics = ['accuracy']\n",
        ")\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen =  ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        ")\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "train_dataset = train_datagen.flow_from_directory(training_path,target_size = (224,224),batch_size = 32,)\n",
        "test_dataset = test_datagen.flow_from_directory(testing_path,target_size = (224,224),batch_size = 32,)\n",
        "\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data = test_dataset,\n",
        "    epochs = 50,\n",
        "    steps_per_epoch = len(train_dataset),\n",
        "    validation_steps = len(test_dataset)\n",
        "\n",
        ")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaBqV4fu60hv"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ces6OvTCJ7NM"
      },
      "source": [
        "history_dict = history.history\n",
        "print(history_dict.keys())\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "acc = history_dict['accuracy']\n",
        "epochs = range(1,len(acc)+1)\n",
        "plt.plot(epochs, loss_values, label = \"Training loss\")\n",
        "plt.plot(epochs, val_loss_values,label = 'Validation loss')\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.savefig(\"resnettLossvsvLoss.jpeg\")\n",
        "plt.show()\n",
        " \n",
        "accuracy = history_dict['accuracy']\n",
        "val_accuracy = history_dict['val_accuracy']\n",
        "plt.plot(epochs, accuracy, label = 'Training accuracy')\n",
        "plt.plot(epochs, val_accuracy, label = 'Validation accuracy')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.savefig(\"resnetTaccuraVsVaccuracy.jpeg\")\n",
        "plt.show()\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(model.history.history)\n",
        "df.to_csv('resnet50.csv')\n",
        "model.save('resnet50.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}